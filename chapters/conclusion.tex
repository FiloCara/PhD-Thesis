\chapter*{Conclusion}
\markboth{\MakeUppercase{Conclusion}}{\MakeUppercase{Conclusion}}
\addcontentsline{toc}{chapter}{Conclusion}

The future direction of the manufacturing industry is to transform industrial processes and products, moving from the reliance on experience-based decision making towards data-centric or evidence-based decision making. It is through this process that machine learning will play a major role to advance the digitisation of traditional industrial systems. In this research work, we have demonstrated how machine learning can contribute to a continuous quality improvement process. Internally collected plant data, as well as new sources of data coming from new sensors may be leveraged through machine learning to model the relationship between input process data and output quality data. We claim that the improvement of the overall quality of a production line can be obtained by working either on process or on quality control. This, for us, definitely makes sense as the production of a part compliant with the specifications is the result of a careful work in optimising the production process, as well as the ability to quickly identify a deviation in quality of the finished part. By identifying a quality problem early on, it is possible to react faster and adjust the process, thus limiting the production of non-conforming parts.

Our dissertation is developed as follow. In Chapter \ref{Industrial Context and Research Framework}, we have emphasised the importance of the ever-growing amount of data available in manufacturing plants. Subsequently, the industrial context of the extrusion blow-moulding is presented. Extrusion blow-moulding is a complex manufacturing process which consists of two sub-processes: the extrusion and the blow-moulding. The large number of degrees of freedom of this manufacturing process is captured by a large number of process parameters that allows to define the process status at a given instant in time. Fuel tanks produced through this manufacturing process must respect some dimensional and geometrical constraints to ensure the integrity of the part and to comply with the costumer specifications. In order to assess the conformity of the part, thickness measurement are routinely performed. Measuring thickness in real-time is a time-consuming task that cannot be done online. For that reason, only certain parts of the entire production batch are measured. Historically, the weight of the tank is used as an alternative of the thickness to assess that the plastic shell is made of sufficient material to ensure its robustness. Compared to thickness, tank weight is easily measurable online. A literature review targeting the quality improvement domain in extrusion blow-moulding has been conducted to evaluate previous works and to define the starting point of our research work. Due to the complexity of the manufacturing process, data-driven methods has proven to be preferable compared to expertise-based methods. 

Chapter \ref{Machine Learning for Quality Control} describes a general data-driven framework that can be used to leverage past manufacturing data to try to improve the quality of parts produced. This approach is composed of four main stages: data collection, data processing, exploratory data analysis and supervised machine learning modelling. Unsupervised learning could be used in other industrial problems, for example to detect unstable operating conditions in a production process, but for our research question, we need supervised learning to infer the relationship between input process data and part quality.

Linear models, penalised or not, tree-based methods and Support Vector Machines are well known supervised learning algorithm that lend themselves very well to be used with structured data. Deep learning, a sub-field of machine learning, however, provides the best results when input data is unstructured. For instance, when dealing with images, videos or time series, state-of-the-art result often rely on deep learning. However, deep learning architectures require a large amount of data to converge towards a stable solution. Transfer learning can partially mitigate this limitation.

In Chapter \ref{From Corrective to Predictive Process Control}, we presented a first application of the proposed method to our industrial case. We chose to work on the prediction of the weight of the tank from the process parameters. A model capable of inferring the weight of the vessel could improve our understanding of the industrial process. The length of the parison, which is considered in the literature as one of the key parameters to explain the dimensional variability of the part, was not available. A system based on a camera and a deep learning algorithm for the detection of the parison of objects was implemented to estimate its length in real time. The estimated length, together with other process parameters, constitute the input to the model. The experiments revealed a number of difficulties. In particular, we were unable to find a usable predictor of the weight of the products produced from the process parameters historically monitored to control the process. Possible explanations have been discussed: the non-stationarity of our process and, above all, the lack of data about raw material. Nonetheless, this research work has enabled us to identify some areas for improvement in the production process. The \textit{SmartBMM} project started from the observation that most of scraps are produced in transient regimes, when the machine state is not yet stable. As a consequence, we fully automated the way the extrusion blow-moulding machines are started, in order to reduce the duration of the transient phase. The project was then extended to automate and optimise other machine phases, such as the purge phase.

Chapter \ref{Thickness inference using thermal imaging} presents another problem, for which we have found a workable a solution. It is to infer the thickness of the part instead of relying on the tank weight. Firstly, a statistical analysis has shown that the correlation between the weight and the thicknesses of the tank is quite low. This calls into question the relevance of using the weight to decide on the conformity of the part. We have therefore proposed a method of inferring the thickness of the tank, in real time, based on thermal imaging and machine learning. Depending on their thickness, the zones of the part cool differently: cooling is faster in thin zones than in thick ones. In thicker areas, the surface temperature even starts to increase before decreasing. This phenomenon is due to the release of energy from the innermost plastic layer that has not be in direct contact with the mould surfaces. The surface temperature is easily measured by thermal imaging. Three different pipelines have been presented. The first leverages parametric expansions to compress information of the temperature time series extracted from each critical point. The parameters of the parametric expansions are then fed into a machine learning algorithm. The second pipeline directly exploits the extracted time series using a recurrent neural network. The third pipeline, which completely outperforms the two previous ones, directly processes the input video without extracting the temperature time series. Finally, we proposed some directions that appear as promising to extend the thickness reconstruction to others points outside the critical ones. In particular, we introduced an approach that could be applied in order to reconstruct the entire thickness mask of the part.


\section*{Scientific contributions}

This research work presents three main scientific contributions.

We propose new industrial applications of machine learning and deep learning for quality improvement. Our work highlights not only the benefits that machine learning approaches can bring to the manufacturing production line, but also the limits of these methods in industrial contexts where the distribution of examples varies. 

We provide a new approach for measuring the thickness of hollow parts, in real-time and without contact. Our approach is based on the exploitation of thermal imaging by deep learning to infer the thickness of a blow-moulded fuel tank. Thermal imaging has been used to infer the thickness of an object before, but to our knowledge, this is the first time a data-driven method has been used to infer thickness based on the decay of surface temperature. We believe that such an approach could be extended to other manufacturing production processes where the manufactured parts are subject to a cooling process.    

We have shown how deep learning can be exploited in the manufacturing industry, even when the amount of data available is limited. Transfer learning and data augmentation have proven to be effective techniques to address the quality data scarcity issue.  

\section*{Industrial contributions}

This research work presents five main industrial contributions:

We provided the company with a new data-driven culture based on machine learning. This approach opens up new possibilities in terms of quality control and process improvement. This thesis focuses on the application to extrusion blow-moulding, but the same approach could be applied to other production processes. For instance, such a framework is currently used in  finishing centres of the production line to assess the quality of welded parts.

The results presented throughout this research work have helped to revise certain beliefs about the functioning of the extrusion blow-moulding process. The critical process parameters, as collected today, are not sufficient to explain the part weight variability. Moreover, it has been found that the weight is not sufficient to ensure correct material distribution. 

The \textit{SmartBMM} software is currently in deployment in all the manufacturing plants of the company. Daily use in the pilot plants, where the solution has been developed, has shown a significant reduction in purge cycle time and starting phases. This reduction in cycle time results in a reduction in part non-conformities.

The parison length provides interesting information about the process. Initiatives are currently in progress to exploit the real-time measurement of this length to adjust the die-gap opening according to the length of the parison. This would allow a more regular distribution of material along the parison length. 

We propose an approach to infer the thickness of blow-moulded parts using thermal imaging and a deep learning without any direct measurement of the part thickness. The results are considered sufficiently accurate to move towards the industrialisation of the proposed system. Such an approach would allow the thorough inspection of all parts.   

\section*{Perspectives}

Finally, we would like to draw attention to some research directions. In our opinion, there are three major challenges for the manufacturing industry to properly apply machine learning models in production: the machine learning model accuracy management, the machine learning life-cycle management and the model generalisation across different machines. These topics need to be addressed in order to answer the third project objective presented in the Section \ref{Research objectives and methodology}.

If we want to employ machine learning to monitor the operation of a production process or to assess the quality of a manufactured part, we must be extremely careful with mission-critical tasks, which necessitate models with a very high accuracy. For instance, for a manufacturing company with low percentage of quality scraps, a machine learning model with a 80\% accuracy in prediction will lead to many incorrect alerts. Not detecting bad parts, or declaring a part as non-compliant when in fact it is fully compliant, would be problematic for the company. The experiments conducted during this research work have highlighted how extremely hard it is to use machine learning in the context of our manufacturing process. We claim that a 100\% model accuracy is not only utopian in our industrial context, but in general in the manufacturing industry. Therefore, we think the in most cases machine learning models could not be able to completely replace the quality inspection performed by a human operator. These methods will rather be used as a tool to help diagnose quality problems. Future works will focus on how a model with a limited accuracy could provide value to a company.

Another topic related to decision making is the life-cycle management of machine learning models. Results presented in Chapter \ref{From Corrective to Predictive Process Control} of this PhD dissertation have highlighted that the extrusion blow-moulding process is non-stationary. In the manufacturing industry, multiple non controllable factors can lead to a change in the input data distribution. If the input data distribution changes over time, a model will not be able to provide the same accuracy over time. Therefore, it is crucial to correctly monitor this data distribution change, possibly re-training the model. In order to re-train the model, new quality control data are needed to fit the model. Moreover, future research works could take advantage of \textit{domain adaptation}, which is a particular case of transfer learning that utilises labelled data in one or more relevant source domains to execute new tasks in a target domain. The common algorithms for shallow domain adaptation can mainly be categorised into two classes: instance-based \citep{bruzzone2009domain,chu2013selective} and feature-based \citep{gheisari2015unsupervised, gong2013connecting, pan2010domain}. The first class reduces the discrepancy between domains by re-weighting the source samples, and it trains on the weighted source samples. For the second class, a common shared space is generally learned in which the distributions of the two datasets are matched. These types of approaches could be used to limit the amount of new samples needed to re-train the model over time.

One last topic that should be addressed in the context of the presented research work is the generalisation across different machines or productions. For a company like Plastic Omnium, it would be interesting to deploy a single machine learning model in different production plants. Unfortunately, a machine learning model trained on a specific machine will not necessarily work for another machine. Some external factors that are not controlled may change. For instance, the input raw material may have slightly different properties, or the room temperature may change across different plants. This means that a lot of time and energy is needed to get training data in each plant of the company. We think that transfer learning could partially solve this problem. Instead of training a model from scratch, we can use a pre-trained model on data from another machine or production. In this way, the model should achieve an accuracy that makes it usable with a limited number of training samples.     

\clearpage